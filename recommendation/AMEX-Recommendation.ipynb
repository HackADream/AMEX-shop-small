{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our recommendation system uses collaborative filtering, which is generally used in successful recommendation system nowadays. In simple term, the approach checks if a user has some similar preferences and dislikes of certain items with other user. If it does, then it assumes that the user will have similar opinion on other items with the other user. Through this approach, the system can predict the opinions of user on the items that user hasnâ€™t bought.  \n",
    "\n",
    "Given that we have the data of users, their ratings on the items they bought (rating depends on their ratings on feedback section or amount of purchases) and the geolocation of the items, our recommendation system will predict the preferences level of users on each of the items. \n",
    "\n",
    "We are using Pytorch to build the deep learning neural network model, which helps us infer the similarities of preferences between users and predict the preferences of all items for every users. The input of our existing data will be modified to replace strings with numbers, so it can be read easily by the neural network model.  \n",
    "\n",
    "Firstly, we import the neccessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import math\n",
    "import copy\n",
    "import pickle\n",
    "import zipfile\n",
    "from textwrap import wrap\n",
    "from pathlib import Path\n",
    "from itertools import zip_longest\n",
    "from collections import defaultdict\n",
    "from urllib.error import URLError\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F \n",
    "from torch.optim.lr_scheduler import _LRScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the two datasets, which we created from the Data Preparation code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rating = pd.read_csv(\"user_rating.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset may consists of strings, which have to be converted integers to be easily processed by the neural network model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(ratings, top=None):\n",
    "    if top is not None:\n",
    "        ratings.groupby('UserID')['Rating'].count()\n",
    "    \n",
    "    unique_users = ratings.UserID.unique()\n",
    "    user_to_index = {old: new for new, old in enumerate(unique_users)}\n",
    "    new_users = ratings.UserID.map(user_to_index)\n",
    "    \n",
    "    unique_items = ratings.ItemID.unique()\n",
    "    item_to_index = {old: new for new, old in enumerate(unique_items)}\n",
    "    new_items = ratings.ItemID.map(item_to_index)\n",
    "    \n",
    "    unique_postcode = ratings.Postcode.unique()\n",
    "    postcode_to_index = {old: new for new, old in enumerate(unique_postcode)}\n",
    "    new_postcode = ratings.Postcode.map(postcode_to_index)\n",
    "\n",
    "    n_users = unique_users.shape[0]\n",
    "    n_items = unique_items.shape[0]\n",
    "    n_postcode = unique_postcode.shape[0]\n",
    "    \n",
    "    X = pd.DataFrame({'UserID': new_users, 'ItemID': new_items, 'Postcode': new_postcode})\n",
    "    y = ratings['Rating'].astype(np.float32)\n",
    "    return (n_users, n_items, n_postcode), (X, y), (user_to_index, item_to_index, postcode_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: 500 users, 500 items, 10 postcode\n",
      "Dataset shape: (124738, 3)\n",
      "Target shape: (124738,)\n"
     ]
    }
   ],
   "source": [
    "(n, m, l), (X, y), _ = create_dataset(data_rating)\n",
    "print(f'Embeddings: {n} users, {m} items, {l} postcode')\n",
    "print(f'Dataset shape: {X.shape}')\n",
    "print(f'Target shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewsIterator:\n",
    "    \n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
    "        X, y = np.asarray(X), np.asarray(y)\n",
    "        \n",
    "        if shuffle:\n",
    "            index = np.random.permutation(X.shape[0])\n",
    "            X, y = X[index], y[index]\n",
    "            \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.n_batches = int(math.ceil(X.shape[0] // batch_size))\n",
    "        self._current = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "    \n",
    "    def next(self):\n",
    "        if self._current >= self.n_batches:\n",
    "            raise StopIteration()\n",
    "        k = self._current\n",
    "        self._current += 1\n",
    "        bs = self.batch_size\n",
    "        return self.X[k*bs:(k + 1)*bs], self.y[k*bs:(k + 1)*bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(X, y, bs=32, shuffle=True):\n",
    "    for xb, yb in ReviewsIterator(X, y, bs, shuffle):\n",
    "        xb = torch.LongTensor(xb)\n",
    "        yb = torch.FloatTensor(yb)\n",
    "        yield xb, yb.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[201, 410,   6],\n",
      "        [357,  37,   0],\n",
      "        [147, 131,   1],\n",
      "        [380, 242,   0]])\n",
      "tensor([[2.],\n",
      "        [0.],\n",
      "        [4.],\n",
      "        [4.]])\n"
     ]
    }
   ],
   "source": [
    "for x_batch, y_batch in batches(X, y, bs=4):\n",
    "    print(x_batch)\n",
    "    print(y_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "datasets = {'train': (X_train, y_train), 'val': (X_valid, y_valid)}\n",
    "dataset_sizes = {'train': len(X_train), 'val': len(X_valid)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = [data_rating.Rating.min(), data_rating.Rating.max()]\n",
    "minmax = torch.Tensor(minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a neural network with embedding layers, hidden layers and dropout layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Creates a dense network with embedding layers.\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "        n_users:            \n",
    "            Number of unique users in the dataset.\n",
    "\n",
    "        n_items: \n",
    "            Number of unique items in the dataset.\n",
    "        \n",
    "        n_postcodes: \n",
    "            Number of unique postcodes in the dataset.\n",
    "\n",
    "        n_factors: \n",
    "            Number of columns in the embeddings matrix.\n",
    "\n",
    "        embedding_dropout: \n",
    "            Dropout rate to apply right after embeddings layer.\n",
    "\n",
    "        hidden:\n",
    "            A single integer or a list of integers defining the number of \n",
    "            units in hidden layer(s).\n",
    "\n",
    "        dropouts: \n",
    "            A single integer or a list of integers defining the dropout \n",
    "            layers rates applyied right after each of hidden layers.\n",
    "            \n",
    "    \"\"\"\n",
    "    def __init__(self, n_users, n_items, n_postcodes,\n",
    "                 n_factors=50, embedding_dropout=0.02, \n",
    "                 hidden=10, dropouts=0.2):\n",
    "        \n",
    "        super().__init__()\n",
    "        hidden = get_list(hidden)\n",
    "        dropouts = get_list(dropouts)\n",
    "        n_last = hidden[-1]\n",
    "        \n",
    "        def gen_layers(n_in):\n",
    "            \"\"\"\n",
    "            A generator that yields a sequence of hidden layers and \n",
    "            their activations/dropouts.\n",
    "            \n",
    "            Note that the function captures `hidden` and `dropouts` \n",
    "            values from the outer scope.\n",
    "            \"\"\"\n",
    "            nonlocal hidden, dropouts\n",
    "            assert len(dropouts) <= len(hidden)\n",
    "            \n",
    "            for n_out, rate in zip_longest(hidden, dropouts):\n",
    "                yield nn.Linear(n_in, n_out)\n",
    "                yield nn.ReLU()\n",
    "                if rate is not None and rate > 0.:\n",
    "                    yield nn.Dropout(rate)\n",
    "                n_in = n_out\n",
    "            \n",
    "        self.u = nn.Embedding(n_users, n_factors)\n",
    "        self.m = nn.Embedding(n_items, n_factors)\n",
    "        self.p = nn.Embedding(n_postcodes, n_factors)\n",
    "        self.drop = nn.Dropout(embedding_dropout)\n",
    "        self.hidden = nn.Sequential(*list(gen_layers(n_factors * 3)))\n",
    "        self.fc = nn.Linear(n_last, 1)\n",
    "        self._init()\n",
    "        \n",
    "    def forward(self, users, items, postcodes, minmax=None):\n",
    "        features = torch.cat([self.u(users), self.m(items), self.p(postcodes)], dim=1)\n",
    "        x = self.drop(features)\n",
    "        x = self.hidden(x)\n",
    "        out = torch.sigmoid(self.fc(x))\n",
    "        if minmax is not None:\n",
    "            min_rating, max_rating = minmax\n",
    "            out = out*(max_rating - min_rating + 1) + min_rating - 0.5\n",
    "        return out\n",
    "    \n",
    "    def _init(self):\n",
    "        \"\"\"\n",
    "        Setup embeddings and hidden layers with reasonable initial values.\n",
    "        \"\"\"\n",
    "        \n",
    "        def init(m):\n",
    "            if type(m) == nn.Linear:\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "                m.bias.data.fill_(0.01)\n",
    "                \n",
    "        self.u.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.m.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.p.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.hidden.apply(init)\n",
    "        init(self.fc)\n",
    "    \n",
    "    \n",
    "def get_list(n):\n",
    "    if isinstance(n, (int, float)):\n",
    "        return [n]\n",
    "    elif hasattr(n, '__iter__'):\n",
    "        return list(n)\n",
    "    raise TypeError('layers configuraiton should be a single number or a list of numbers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = EmbeddingNet(\n",
    "    n_users=n, n_items=m, n_postcodes= l,\n",
    "    n_factors=150, hidden=[500, 500, 500], \n",
    "    embedding_dropout=0.05, dropouts=[0.5, 0.5, 0.25])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Train the neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss improvement on epoch: 1\n",
      "[001/100] train: 9.2756 - val: 8.9915\n",
      "[002/100] train: 8.9774 - val: 9.0117\n",
      "[003/100] train: 8.9346 - val: 9.0254\n",
      "[004/100] train: 8.9165 - val: 9.0412\n",
      "[005/100] train: 8.8748 - val: 9.1082\n",
      "[006/100] train: 8.8046 - val: 9.1341\n",
      "[007/100] train: 8.7121 - val: 9.1993\n",
      "[008/100] train: 8.5703 - val: 9.3576\n",
      "[009/100] train: 8.3385 - val: 9.5715\n",
      "[010/100] train: 8.1186 - val: 9.8119\n",
      "[011/100] train: 7.8230 - val: 9.9129\n",
      "early stopping after epoch 011\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "wd = 1e-5\n",
    "bs = 2000\n",
    "n_epochs = 100\n",
    "patience = 10\n",
    "no_improvements = 0\n",
    "best_loss = np.inf\n",
    "best_weights = None\n",
    "history = []\n",
    "lr_history = []\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net.to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)\n",
    "iterations_per_epoch = int(math.ceil(dataset_sizes['train'] // bs))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    stats = {'epoch': epoch + 1, 'total': n_epochs}\n",
    "    \n",
    "    for phase in ('train', 'val'):\n",
    "        training = phase == 'train'\n",
    "        running_loss = 0.0\n",
    "        n_batches = 0\n",
    "        \n",
    "        for batch in batches(*datasets[phase], shuffle=training, bs=bs):\n",
    "            x_batch, y_batch = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # compute gradients only during 'train' phase\n",
    "            with torch.set_grad_enabled(training):\n",
    "                outputs = net(x_batch[:, 0], x_batch[:, 1], x_batch[:, 2], minmax)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                \n",
    "                # don't update weights and rates when in 'val' phase\n",
    "                if training:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        stats[phase] = epoch_loss\n",
    "        \n",
    "        # early stopping: save weights of the best model so far\n",
    "        if phase == 'val':\n",
    "            if epoch_loss < best_loss:\n",
    "                print('loss improvement on epoch: %d' % (epoch + 1))\n",
    "                best_loss = epoch_loss\n",
    "                best_weights = copy.deepcopy(net.state_dict())\n",
    "                no_improvements = 0\n",
    "            else:\n",
    "                no_improvements += 1\n",
    "                \n",
    "    history.append(stats)\n",
    "    print('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "    if no_improvements >= patience:\n",
    "        print('early stopping after epoch {epoch:03d}'.format(**stats))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(best_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate the loss function to see the overall performances of the training of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['val'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], x_batch[:, 2], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final RMSE: 3.0565\n"
     ]
    }
   ],
   "source": [
    "final_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Final RMSE: {final_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best.weights', 'wb') as file:\n",
    "    pickle.dump(best_weights, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to predict the preferences of User 1 for all items. Our input will be User 1 (list of 1s), list of items and list of items' corresponding postcode. For each element in the output tensor, the higher the value, the higher the preference value for its corresponding item.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "user = torch.tensor([1] * 500)\n",
    "data_items = pd.read_csv(\"list_items.csv\")\n",
    "\n",
    "item_list = []\n",
    "postcode_list = []\n",
    "price_list = []\n",
    "\n",
    "for data_val in data_items.values.tolist():\n",
    "    item_list.append(data_val[0]-1)\n",
    "    postcode_list.append(data_val[1])\n",
    "    price_list.append(data_val[2])\n",
    "\n",
    "item = torch.tensor(item_list)\n",
    "\n",
    "unique_postcode = set(postcode_list)\n",
    "postcode_to_index = {old: new for new, old in enumerate(unique_postcode)}\n",
    "new_postcode = list(map(lambda x: postcode_to_index[x],postcode_list))\n",
    "\n",
    "postcode = torch.tensor(new_postcode)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = net(user,item, postcode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the output now. We create a dict where we map each items to its output score, which is the rating. Our rating is 0-1 instead of 1-10 because we implemented sigmoid function in our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list = list(output.numpy().flatten())\n",
    "item_rating = {}\n",
    "\n",
    "for i in range(0,499):\n",
    "    item_rating[i] = output_list[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we sorted the dict by its rating in reverse order. In the user preference list, the first item has the highest preferences from User 1 and the last item has the lowest preferences from User 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(151, 0.32776675), (46, 0.32776558), (400, 0.32734692), (127, 0.32731152), (308, 0.32690844), (209, 0.32636848), (222, 0.32605797), (270, 0.3259815), (3, 0.32568696), (347, 0.3256444), (379, 0.32547078), (47, 0.3253154), (361, 0.32456896), (489, 0.32437065), (273, 0.3242113), (52, 0.32391176), (101, 0.32371026), (199, 0.32366723), (369, 0.32362142), (43, 0.32357666), (99, 0.3230511), (97, 0.32275176), (442, 0.322703), (15, 0.3226415), (145, 0.3225865), (319, 0.3223825), (85, 0.32210967), (125, 0.32206538), (7, 0.32196733), (255, 0.32157212), (386, 0.3215071), (444, 0.32145277), (131, 0.3214325), (251, 0.3213563), (404, 0.3209261), (141, 0.32084996), (166, 0.3208201), (5, 0.3207341), (402, 0.3207108), (437, 0.32046977), (248, 0.32040095), (252, 0.32020247), (443, 0.3201325), (205, 0.32011893), (304, 0.32002583), (474, 0.32000145), (491, 0.31999835), (419, 0.31995717), (28, 0.3197675), (375, 0.31975064), (453, 0.31968692), (144, 0.31965125), (213, 0.31948248), (228, 0.31947926), (429, 0.31944942), (413, 0.31917346), (398, 0.31913245), (268, 0.31904733), (310, 0.31895772), (103, 0.31871137), (12, 0.31863254), (232, 0.31855994), (178, 0.31854114), (148, 0.31843498), (346, 0.31838077), (456, 0.31830812), (418, 0.31819984), (66, 0.3180563), (335, 0.31799975), (155, 0.31787917), (207, 0.31780374), (272, 0.31755057), (480, 0.31750455), (349, 0.31747448), (389, 0.31741145), (299, 0.31736732), (403, 0.31731763), (283, 0.3172756), (172, 0.31720433), (21, 0.31711587), (325, 0.31706315), (275, 0.31705764), (86, 0.31688112), (107, 0.31681892), (26, 0.3166844), (61, 0.31665984), (57, 0.31662738), (49, 0.31639755), (173, 0.31633827), (147, 0.3163202), (260, 0.31619504), (17, 0.31618688), (301, 0.31599605), (231, 0.31596497), (105, 0.31591475), (300, 0.3159022), (436, 0.3158003), (426, 0.31577155), (344, 0.3157291), (394, 0.3156572), (256, 0.31558996), (492, 0.31556913), (473, 0.31546798), (35, 0.31539813), (204, 0.3153846), (331, 0.31537938), (18, 0.31537667), (391, 0.31531572), (243, 0.31525862), (463, 0.31525725), (200, 0.31525695), (80, 0.31521013), (441, 0.3152066), (466, 0.31520405), (454, 0.31516477), (305, 0.3150748), (407, 0.31506956), (431, 0.31494537), (210, 0.3149395), (34, 0.31493673), (401, 0.31486243), (201, 0.31477693), (50, 0.31474987), (280, 0.31473312), (405, 0.31458995), (152, 0.31450573), (448, 0.31445888), (116, 0.3144253), (451, 0.31432322), (38, 0.3142212), (484, 0.31415015), (496, 0.31414774), (356, 0.31413674), (171, 0.31413054), (279, 0.31411532), (214, 0.31410706), (302, 0.31389686), (371, 0.31386), (134, 0.3137859), (39, 0.31377807), (430, 0.3137503), (227, 0.31365216), (486, 0.31362936), (128, 0.31349927), (378, 0.3134923), (10, 0.3134792), (149, 0.31345925), (287, 0.31323585), (345, 0.31317824), (294, 0.3131321), (459, 0.31312042), (70, 0.31311825), (23, 0.3130918), (160, 0.3130905), (350, 0.31300777), (411, 0.3130046), (440, 0.31293407), (62, 0.31293303), (130, 0.31288847), (93, 0.31280956), (114, 0.3127972), (104, 0.3127898), (340, 0.31268036), (229, 0.31262386), (124, 0.3126114), (428, 0.3125757), (359, 0.312571), (494, 0.3125386), (291, 0.31245628), (81, 0.3124029), (298, 0.31238613), (98, 0.3123778), (370, 0.3123668), (481, 0.312338), (332, 0.31233576), (242, 0.31231916), (262, 0.31227067), (126, 0.31226805), (309, 0.31222463), (63, 0.31211182), (84, 0.31209078), (278, 0.31208637), (75, 0.31196097), (100, 0.31193998), (16, 0.31192723), (241, 0.311921), (24, 0.3118162), (274, 0.31179243), (296, 0.31170782), (425, 0.31170225), (68, 0.31166893), (168, 0.31157792), (95, 0.31156942), (265, 0.3115243), (74, 0.31147072), (157, 0.31142062), (194, 0.31133375), (196, 0.311294), (174, 0.31127104), (392, 0.3112359), (67, 0.31122702), (295, 0.31121594), (412, 0.31121355), (115, 0.31109908), (1, 0.3110486), (154, 0.31102037), (239, 0.3109874), (94, 0.3109738), (312, 0.31094593), (465, 0.31091395), (139, 0.3108812), (206, 0.31084037), (311, 0.31081748), (323, 0.31081256), (223, 0.31072393), (460, 0.31069452), (156, 0.3106859), (87, 0.31067914), (221, 0.31056064), (121, 0.3105495), (366, 0.31054467), (150, 0.31048292), (37, 0.31047112), (77, 0.31044146), (253, 0.31037283), (250, 0.31031004), (261, 0.31021637), (475, 0.3102103), (89, 0.31017995), (2, 0.3101485), (20, 0.31011736), (238, 0.31010747), (320, 0.31009245), (464, 0.31009182), (40, 0.31008905), (351, 0.31003264), (322, 0.31001744), (216, 0.31001624), (161, 0.31001303), (82, 0.3099881), (112, 0.3099425), (226, 0.30990916), (352, 0.30989257), (197, 0.3098341), (36, 0.30976924), (60, 0.30970547), (445, 0.30960956), (408, 0.30960667), (30, 0.30953026), (471, 0.30952555), (338, 0.30949903), (377, 0.3094653), (64, 0.3094504), (218, 0.309205), (202, 0.30919436), (51, 0.30912548), (41, 0.30911735), (362, 0.30909052), (353, 0.30908144), (330, 0.3089695), (4, 0.3089027), (191, 0.30885845), (136, 0.30881244), (495, 0.30880603), (399, 0.3088019), (129, 0.30877757), (122, 0.30875245), (341, 0.30872783), (364, 0.30870503), (146, 0.3086898), (317, 0.30856523), (396, 0.3084472), (111, 0.3084072), (483, 0.30840114), (258, 0.3083901), (233, 0.30836576), (118, 0.30835828), (313, 0.3083546), (90, 0.3083151), (176, 0.30829978), (373, 0.3082334), (286, 0.30819288), (153, 0.30814642), (357, 0.30809033), (132, 0.30808315), (45, 0.3079975), (230, 0.3079813), (192, 0.30796257), (406, 0.30794853), (470, 0.30793333), (110, 0.30788746), (163, 0.30787477), (143, 0.30784696), (477, 0.30778557), (76, 0.30778548), (318, 0.3077558), (337, 0.30770555), (354, 0.30769962), (271, 0.30766368), (348, 0.3076567), (179, 0.30760917), (187, 0.30760285), (447, 0.30759242), (180, 0.30755594), (140, 0.30749336), (208, 0.307489), (170, 0.30745998), (383, 0.30743966), (376, 0.3073297), (165, 0.30727533), (420, 0.30725637), (215, 0.3071769), (292, 0.30706167), (83, 0.30697855), (91, 0.30696958), (324, 0.30687463), (158, 0.30686498), (355, 0.3068118), (55, 0.30678046), (219, 0.3067725), (102, 0.30672953), (245, 0.30671582), (108, 0.3067096), (469, 0.30663964), (316, 0.30663738), (380, 0.3066362), (363, 0.30662212), (388, 0.30662146), (479, 0.3066071), (365, 0.30660048), (9, 0.30656752), (449, 0.30655244), (297, 0.30653223), (138, 0.30650613), (485, 0.30650565), (183, 0.3064331), (281, 0.3063534), (342, 0.30618343), (189, 0.30613166), (490, 0.30611557), (421, 0.3061074), (315, 0.30608028), (422, 0.30604592), (368, 0.30594215), (487, 0.30592254), (326, 0.30591884), (14, 0.30585185), (186, 0.30582836), (446, 0.30581945), (142, 0.3058036), (135, 0.30579472), (22, 0.30565327), (269, 0.3055933), (482, 0.30555543), (321, 0.3055261), (288, 0.30547035), (247, 0.30543727), (358, 0.30542567), (44, 0.30531704), (372, 0.30530453), (360, 0.3052175), (417, 0.3052112), (33, 0.3051563), (53, 0.30510417), (42, 0.30508128), (472, 0.3050374), (73, 0.30499473), (435, 0.30496764), (257, 0.30496523), (266, 0.30495834), (439, 0.3049043), (137, 0.30486524), (27, 0.30486318), (329, 0.30484197), (450, 0.30480018), (387, 0.3047432), (307, 0.304732), (468, 0.30472812), (488, 0.3046952), (220, 0.30468762), (438, 0.30442283), (493, 0.30442166), (455, 0.30435586), (224, 0.3043205), (69, 0.30427197), (434, 0.30419424), (109, 0.3041875), (11, 0.30409837), (225, 0.3040291), (31, 0.303967), (217, 0.30389687), (0, 0.30384275), (478, 0.3038401), (461, 0.30380133), (48, 0.30379644), (162, 0.30379128), (119, 0.303733), (314, 0.3036934), (462, 0.3036262), (395, 0.30352163), (410, 0.30350393), (390, 0.30340996), (25, 0.3034078), (284, 0.30326205), (328, 0.30325943), (290, 0.30307576), (56, 0.30297327), (188, 0.3029541), (123, 0.30288097), (381, 0.30273157), (427, 0.3026793), (79, 0.3026326), (184, 0.3026011), (259, 0.30258086), (113, 0.30254123), (497, 0.3024042), (8, 0.302331), (424, 0.3022303), (476, 0.30214122), (264, 0.30213663), (195, 0.30202734), (185, 0.301909), (267, 0.30177084), (32, 0.3016311), (415, 0.30162647), (382, 0.30156794), (249, 0.30156595), (133, 0.30146524), (169, 0.30130026), (190, 0.30127773), (193, 0.30125868), (293, 0.3012339), (303, 0.30096284), (393, 0.30077794), (306, 0.3006991), (106, 0.30069137), (54, 0.3006222), (240, 0.3005603), (237, 0.3003756), (254, 0.3003483), (336, 0.30021712), (374, 0.3002009), (29, 0.30009893), (203, 0.29991022), (333, 0.29990947), (198, 0.29980117), (384, 0.2997017), (175, 0.29956895), (19, 0.2995091), (457, 0.29938066), (397, 0.29932535), (285, 0.29906985), (416, 0.29899552), (334, 0.2989213), (452, 0.29874942), (339, 0.29871082), (167, 0.29863063), (343, 0.29851136), (282, 0.2984448), (458, 0.2983673), (467, 0.29830292), (414, 0.298223), (59, 0.29810008), (71, 0.2979198), (327, 0.29782704), (432, 0.29782155), (263, 0.29777798), (235, 0.29777572), (177, 0.2975829), (277, 0.2973571), (78, 0.29732057), (181, 0.29724553), (164, 0.29704314), (289, 0.29651687), (385, 0.29611918), (96, 0.29595506), (117, 0.2959494), (211, 0.29563853), (236, 0.29540777), (367, 0.29522887), (88, 0.2951355), (159, 0.29493952), (234, 0.29468578), (433, 0.29452822), (120, 0.29422322), (246, 0.2940411), (72, 0.2938739), (58, 0.29330316), (244, 0.29315048), (409, 0.29263264), (276, 0.29252166), (423, 0.2921366), (13, 0.2914965), (182, 0.29064482), (92, 0.28974313), (498, 0.28970253), (212, 0.2893458), (6, 0.28595304), (65, 0.28374)]\n"
     ]
    }
   ],
   "source": [
    "user_preference = sorted(item_rating.items(), key=lambda kv: kv[1], reverse=True)\n",
    "print(user_preference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spending Capability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our recommendation system does not only recommend the items that user likely to give the top rating, but also filter out items out of spending capability. If the price of item is higher than the user's current account balance, the system knows that the user is not going to purchase the item. So the system will not recommend the item. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(46, 0.32776558), (3, 0.32568696), (47, 0.3253154), (52, 0.32391176), (43, 0.32357666), (15, 0.3226415), (7, 0.32196733), (5, 0.3207341), (28, 0.3197675), (12, 0.31863254), (66, 0.3180563), (21, 0.31711587), (26, 0.3166844), (61, 0.31665984), (57, 0.31662738), (49, 0.31639755), (17, 0.31618688), (35, 0.31539813), (18, 0.31537667), (34, 0.31493673), (50, 0.31474987), (38, 0.3142212), (39, 0.31377807), (10, 0.3134792), (70, 0.31311825), (23, 0.3130918), (62, 0.31293303), (63, 0.31211182), (16, 0.31192723), (24, 0.3118162), (68, 0.31166893), (67, 0.31122702), (1, 0.3110486), (37, 0.31047112), (2, 0.3101485), (20, 0.31011736), (40, 0.31008905), (36, 0.30976924), (60, 0.30970547), (30, 0.30953026), (64, 0.3094504), (51, 0.30912548), (41, 0.30911735), (4, 0.3089027), (45, 0.3079975), (55, 0.30678046), (9, 0.30656752), (14, 0.30585185), (22, 0.30565327), (44, 0.30531704), (33, 0.3051563), (53, 0.30510417), (42, 0.30508128), (27, 0.30486318), (69, 0.30427197), (11, 0.30409837), (31, 0.303967), (0, 0.30384275), (48, 0.30379644), (25, 0.3034078), (56, 0.30297327), (8, 0.302331), (32, 0.3016311), (54, 0.3006222), (29, 0.30009893), (19, 0.2995091), (59, 0.29810008), (58, 0.29330316), (13, 0.2914965), (6, 0.28595304), (65, 0.28374)]\n"
     ]
    }
   ],
   "source": [
    "#Assume user has Â£70 remaining on account balance.\n",
    "account_balance = 70\n",
    "\n",
    "for i in range(0, len(price_list)):\n",
    "    if(i > account_balance):\n",
    "        item_to_remove = i\n",
    "        for item in user_preference:\n",
    "            if(item[0]==item_to_remove):\n",
    "                user_preference.remove(item)\n",
    "                break\n",
    "\n",
    "print(user_preference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
